import argparse
import json
import logging
import os
import time
from glob import glob
from typing import Dict, List
from pathlib import Path

from CoNLI.modules.arguments import OpenaiArguments, create_openai_arguments
from CoNLI.modules.hallucination_mitigator import HmResult, HdResult, HallucinationMitigator
from CoNLI.modules.hd_constants import AllHallucinations, FieldName
from CoNLI.modules.utils.logging_utils import init_logging
from CoNLI.modules.utils.conversion_utils import str2bool
from CoNLI.modules.data.data_loader import DataLoader

def rewrite(
        data_ids: List[str],
        raw_responses: Dict[str, str],
        sources: Dict[str, str],
        hd_results: Dict[str, List[HdResult]],
        openai_args: OpenaiArguments,
        config_file: str = None,
    ) -> List[HmResult]:
    # init hallucination mitigator
    hallucination_mitigator = HallucinationMitigator(openai_args = openai_args, config_file = config_file)
    # run hallucination mititgator against enocunters
    results = hallucination_mitigator.mitigate(
        data_ids = data_ids,
        raw_responses = raw_responses,
        sources = sources,
        hd_results = hd_results, 
    )
    return results

def load_hd_result(file_name: str) -> Dict[str, List[HdResult]]:
    hd_results = {}
    # read hd_result jsonl for hallucination mitigation use
    for line in open(file_name):
        data = json.loads(line)
        data_id = data[AllHallucinations.DATA_ID]
        hallucinations = data[AllHallucinations.HALLUCINATIONS]
        hd_results[data_id] = []
        for hallucination in hallucinations:
            hd_results[data_id].append(
                HdResult(
                    hallucinated_sentence = hallucination[FieldName.SENTENCE_TEXT],
                    reason = hallucination[FieldName.REASON],
                    instruction = hallucination[FieldName.REASON], #TODO: convert reason into better mitigation instruction
                    detection_type = hallucination[FieldName.DETECTION_TYPE],
                )
            )
    return hd_results

def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--outputfolder',
        required=True,
        help='Where to output all of this runs data',
        type=str)
    parser.add_argument(
        '--input_hypothesis',
        required=True,
        help='The folder where all of your raw_responses are located',
        type=str)
    parser.add_argument(
        '--input_src',
        required=True,
        help='The folder where all of your sources are located',
        type=str)
    parser.add_argument(
        '--config_file',
        default=(Path(__file__).absolute()).parent/"configs"/"aoai_config.json",
        help='JSON file holding the aoai endpoint configs',
        type=str)   
    parser.add_argument(
        '--config_setting',
        default='gpt-4-32k',
        help='The configuration setting to run against (aoai_config.json)',
        type=str)
    parser.add_argument(
        '--hallucinationjsonl',
        required=True,
        help='The Hallucination jsonl file that was generated by detect_hallucinations.py',
        type=str)
    parser.add_argument(
        '--max_parallel_data',
        default=5,
        help='The maximum number of data to process in parallel.  If set to 1, will run sequentially',
        type=int)
    parser.add_argument(
        '--testmode',
        default=0,
        help='Simple iteration filter for testing.  Will run E2E but only on the first <N> data, specified by this int',
        type=int)      
    parser.add_argument(
        '--do_mitigate',
        default='True',
        help='whether run a evaluation against ground truth sumamry after mitigation',    
        type=str)  
    parser.add_argument(
        '--do_eval',
        default='True',
        help='whether run a evaluation against ground truth sumamry after mitigation',
        type=str)
    
    parser.add_argument('--log_level', default='error')
    parser.add_argument('--logfile_name', default=None)
    args = parser.parse_args()
    args.do_mitigate = str2bool(args.do_mitigate)
    args.do_eval = str2bool(args.do_eval)
    args.max_parallel_data = max(args.max_parallel_data, 1)
    args.testmode = max(args.testmode, 0)
    return args

if __name__ == "__main__":

    args = parse_arguments()
    os.makedirs(args.outputfolder, exist_ok=True)

    init_logging(args.log_level, args.logfile_name)
    dataloader = DataLoader(
        hypothesis=args.input_hypothesis,
        src_folder=args.input_src,
        # testmode=args.testmode
    )

    if args.do_mitigate:
        logging.info('Starting Hallucination Detection')

        openai_args = create_openai_arguments(args.config_setting, args.max_parallel_data, config_file=args.config_file)
        
        print('Enabling parallelism for the tokenizer')
        os.environ['TOKENIZERS_PARALLELISM'] = 'true'
        print('Disabling Azure Telemetry (Doesnt handle parallelism well)')
        os.environ['AZURE_CORE_COLLECT_TELEMETRY'] = 'false'

        start_time = time.time()
        if os.path.isdir(args.hallucinationjsonl):
            args.hallucinationjsonl = glob(f"{args.hallucinationjsonl}/**/allhallucinations.jsonl", recursive=True)[0]
        hd_results = load_hd_result(args.hallucinationjsonl)
        results = rewrite(
            data_ids = list(hd_results.keys())[0:args.testmode] if args.testmode >0 else list(hd_results.keys()),
            raw_responses = dataloader._hypothesis,
            sources = dataloader._src_docs,
            hd_results = hd_results,
            openai_args = openai_args,
            config_file=args.config_file
        )

        for result in results:
            fname = f"{result.data_id}.txt"
            with open(os.path.join(args.outputfolder, fname), 'w') as outF:
                outF.write(result.refined_response)

        end_time = time.time() - start_time
        print('Hallucination mitigation Has Finished')
        print(f'Total wall-clock time: {end_time} seconds')